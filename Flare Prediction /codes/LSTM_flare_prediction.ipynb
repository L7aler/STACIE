{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1927d5b",
   "metadata": {},
   "source": [
    "## Flare prediction with LSTM's\n",
    "This notebook can be used to train a LSTM to perform flare predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79affedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, RNN, LSTM, Flatten, TimeDistributed, LSTMCell, GlobalAveragePooling2D, Input, Dropout, Attention\n",
    "from tensorflow.keras.layers import RepeatVector, Conv2D, SimpleRNN, GRU, Reshape, ConvLSTM2D, Conv2DTranspose, Conv3DTranspose\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.utils import shuffle\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d69647",
   "metadata": {},
   "source": [
    "Upload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977194c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_inp = '/content/gdrive/MyDrive/ADL_project/Flare_Prediction/Multi_label_classification/train_input.npy'\n",
    "file_tar = '/content/gdrive/MyDrive/ADL_project/Flare_Prediction/Multi_label_classification/train_target.npy'\n",
    "train_input = np.load(file_inp)\n",
    "train_target = np.load(file_tar)\n",
    "\n",
    "file_inp = '/content/gdrive/MyDrive/ADL_project/Flare_Prediction/Multi_label_classification/val_input.npy'\n",
    "file_tar = '/content/gdrive/MyDrive/ADL_project/Flare_Prediction/Multi_label_classification/val_target.npy'\n",
    "val_input = np.load(file_inp)\n",
    "val_target = np.load(file_tar)\n",
    "\n",
    "\n",
    "file_inp = '/content/gdrive/MyDrive/ADL_project/Flare_Prediction/Multi_label_classification/test_input.npy'\n",
    "file_tar = '/content/gdrive/MyDrive/ADL_project/Flare_Prediction/Multi_label_classification/test_target.npy'\n",
    "test_input = np.load(file_inp)\n",
    "test_target = np.load(file_tar)\n",
    "\n",
    "\n",
    "train_input, train_target = shuffle(train_input, train_target, random_state=0)  #shuffle training set\n",
    "\n",
    "\n",
    "binary = False  #if you want to treat the problem as a binary problem\n",
    "if binary:\n",
    "    temp = np.zeros(shape = (train_target.shape[0], 1, 2))\n",
    "    i = np.where(train_target[:, :, 0] == 1)[0]\n",
    "    j = np.where(train_target[:, :, 0] != 1)[0]\n",
    "    temp[i, :, 0] = 1\n",
    "    temp[j, :, 1] = 1\n",
    "    train_target = temp\n",
    "\n",
    "    temp = np.zeros(shape = (val_target.shape[0], 1, 2))\n",
    "    i = np.where(val_target[:, :, 0] == 1)[0]\n",
    "    j = np.where(val_target[:, :, 0] != 1)[0]\n",
    "    temp[i, :, 0] = 1\n",
    "    temp[j, :, 1] = 1\n",
    "    val_target = temp\n",
    "\n",
    "    temp = np.zeros(shape = (test_target.shape[0], 1, 2))\n",
    "    i = np.where(test_target[:, :, 0] == 1)[0]\n",
    "    j = np.where(test_target[:, :, 0] != 1)[0]\n",
    "    temp[i, :, 0] = 1\n",
    "    temp[j, :, 1] = 1\n",
    "    test_target = temp\n",
    "    \n",
    "if binary:\n",
    "    train_target = train_target.reshape(77738, 2)\n",
    "    val_target = val_target.reshape(24683, 2)\n",
    "    test_target = test_target.reshape(40858, 2)\n",
    "else:\n",
    "    train_target = train_target.reshape(77738, 5)\n",
    "    val_target = val_target.reshape(24683, 5)\n",
    "    test_target = test_target.reshape(40858, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f50e95e",
   "metadata": {},
   "source": [
    "Customized F1 loss function for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f3abec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a5875a",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd00c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(LSTM(256, input_shape=(10, 40), return_sequences = True))\n",
    "model.add(LSTM(59))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add((Dense(2, activation = 'softmax')))\n",
    "\n",
    "initial_learning_rate = .002\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=False)\n",
    "\n",
    "metric = tfa.metrics.F1Score(num_classes=5, threshold=None)\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=lr_schedule), loss=f1_loss, metrics=['accuracy', metric])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eaa02c",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da94ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_input, train_target, epochs = 20, shuffle=True, batch_size = 500, validation_data = (val_input, val_target) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df52a30",
   "metadata": {},
   "source": [
    "Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5297c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_input)\n",
    "prediction = np.zeros(shape = pred.shape)\n",
    "for i, p in enumerate(pred):\n",
    "  j = np.argmax(p)\n",
    "  prediction[i, j] = 1\n",
    "\n",
    "\n",
    "pred = prediction\n",
    "\n",
    "y_true = np.where(test_target[:, :]==1)[1]\n",
    "y_pred = np.where(pred[:, :]==1)[1]\n",
    "target_names = ['No Flare','Flare']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
