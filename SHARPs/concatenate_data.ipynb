{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecce8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbfc29e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = ['2021.09.01 - 2022.01.01', '2021.06.01 - 2021.09.01', '2021.03.01 - 2021.06.01', '2021.01.01 - 2021.03.01']\n",
    "date2 = ['2020.09.01 - 2021.01.01', '2020.06.01 - 2020.09.01', '2020.03.01 - 2020.06.01', '2020.01.01 - 2020.03.01']\n",
    "date3 = ['2019.09.01 - 2020.01.01', '2019.06.01 - 2019.09.01', '2019.03.01 - 2019.06.01', '2019.01.01 - 2019.03.01']\n",
    "date4 = ['2018.09.01 - 2019.01.01', '2018.06.01 - 2018.09.01', '2018.03.01 - 2018.06.01', '2018.01.01 - 2018.03.01']\n",
    "date5 = ['2017.09.01 - 2018.01.01', '2017.06.01 - 2017.09.01', '2017.03.01 - 2017.06.01', '2017.01.01 - 2017.03.01']\n",
    "date6 = ['2016.09.01 - 2017.01.01', '2016.06.01 - 2016.09.01', '2016.03.01 - 2016.06.01', '2016.01.01 - 2016.03.01']\n",
    "date7 = ['2015.09.01 - 2016.01.01', '2015.06.01 - 2015.09.01', '2015.03.01 - 2015.06.01', '2015.01.01 - 2015.03.01']\n",
    "date8 = ['2014.09.01 - 2015.01.01', '2014.06.01 - 2014.09.01', '2014.03.01 - 2014.06.01', '2014.01.01 - 2014.03.01']\n",
    "date9 = ['2013.09.01 - 2014.01.01', '2013.06.01 - 2013.09.01', '2013.03.01 - 2013.06.01', '2013.01.01 - 2013.03.01']\n",
    "date10 = ['2012.09.01 - 2013.01.01', '2012.06.01 - 2012.09.01', '2012.03.01 - 2012.06.01', '2012.01.01 - 2012.03.01']\n",
    "date11 = ['2011.09.01 - 2012.01.01', '2011.06.01 - 2011.09.01', '2011.03.01 - 2011.06.01', '2011.01.01 - 2011.03.01']\n",
    "date12 = ['2010.09.01 - 2011.01.01', '2010.06.01 - 2010.09.01', '2010.03.01 - 2010.06.01', '2010.01.01 - 2010.03.01']\n",
    "date = date + date2 + date3 + date4 + date5 + date6 + date7 + date8 + date9 + date10 + date11 + date12\n",
    "\n",
    "date.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c27ae246",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/L7aler_HD 1/ADL_Project/AR_data/mag_flux_area_data/set_2/'\n",
    "for i, name in enumerate(date[1:]):\n",
    "    try:\n",
    "        if i == 0:\n",
    "            df = pd.read_csv(path + name + '.csv', index_col = 0)\n",
    "        else:\n",
    "            temp = pd.read_csv(path + name + '.csv', index_col = 0)\n",
    "            df = pd.concat([df, temp])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "df = df.set_index([pd.Index(np.arange(0, len(df), 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4608471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = df['HARPNUM'].unique()\n",
    "\n",
    "path_input = '/Volumes/L7aler_HD 1/ADL_Project/AR_data/mag_flux_area_data/set_2/input_sequences/'\n",
    "path_target = '/Volumes/L7aler_HD 1/ADL_Project/AR_data/mag_flux_area_data/set_2/target_sequences/'\n",
    "\n",
    "\n",
    "data_in_conc = np.zeros(shape = (100, 2))\n",
    "target_conc = np.zeros(shape = (25, 2))\n",
    "\n",
    "c = 0\n",
    "for i, harpnum in enumerate(Id):\n",
    "    l, u = 0, 100   #l is the lower index for the input, u is the upper index for the input (so initially input is elements 0-100)\n",
    "    j = np.where(df['HARPNUM'] == harpnum)[0]\n",
    "    flux = df['USFLUX'][j]\n",
    "    area = df['AREA_ACR'][j]\n",
    "\n",
    "    sequ = 0\n",
    "    while u + 25 < len(j):\n",
    "        data_in = np.zeros(shape = (100, 4))\n",
    "        target = np.zeros(shape = (25, 4))\n",
    "        data_in[:, 0], data_in[:, 1] = flux[l:u], area[l:u]\n",
    "        target[:, 0], target[:, 1] = flux[u:u+25], area[u:u+25]\n",
    "        \n",
    "        \n",
    "        l, u = l + 10, u + 10    #we shift our kernel window by 10 date points for each new sequence\n",
    "        sequ += 1\n",
    "        \n",
    "        name_in = 'i_AR{}_{}.npz'.format(harpnum, sequ)\n",
    "        name_target = 't_AR{}_{}.npz'.format(harpnum, sequ)\n",
    "        #with open(path_input + name_in, 'wb') as f:\n",
    "        #    np.save(f, data_in)\n",
    "        #with open(path_target + name_target, 'wb') as f:\n",
    "        #    np.save(f, target)\n",
    "        \n",
    "        if c == 0:\n",
    "            c += 1\n",
    "            data_in_conc = data_in\n",
    "            target_conc = target\n",
    "        elif c ==1:\n",
    "            c+= 1\n",
    "            data_in_conc = np.concatenate(([data_in_conc], [data_in]))\n",
    "            target_conc = np.concatenate(([target_conc], [target]))\n",
    "        else:\n",
    "            data_in_conc = np.concatenate((data_in_conc, [data_in]))\n",
    "            target_conc = np.concatenate((target_conc, [target]))\n",
    "    \n",
    "\n",
    "    break\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df6f01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_in_conc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d2b81",
   "metadata": {},
   "source": [
    "### If you want to downsample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3785f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spectres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085d6d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.copy(data_in_conc)   #I'm annoyed by this long variable name\n",
    "new_wavs = np.arange(1, 100, 3)\n",
    "spec_wavs = np.arange(0, 100, 1)\n",
    "data_res = np.zeros(shape=(len(data), 33, 2))\n",
    "for i, d in enumerate(data):\n",
    "    data_res[i, :, 0] = spectres.spectres(new_wavs, spec_wavs, d[:, 0], spec_errs=None, fill=None, verbose=True)\n",
    "    data_res[i, :, 1] = spectres.spectres(new_wavs, spec_wavs, d[:, 1], spec_errs=None, fill=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f36bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.copy(target_conc)\n",
    "new_wavs = np.arange(1, 25, 3)\n",
    "spec_wavs = np.arange(0, 25, 1)\n",
    "target_res = np.zeros(shape=(79566, 8, 2))\n",
    "for i, d in enumerate(target):\n",
    "    target_res[i, :, 0] = spectres.spectres(new_wavs, spec_wavs, d[:, 0], spec_errs=None, fill=None, verbose=True)\n",
    "    target_res[i, :, 1] = spectres.spectres(new_wavs, spec_wavs, d[:, 1], spec_errs=None, fill=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a77f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '/Volumes/L7aler_HD 1/ADL_Project/AR_data/mag_flux_area_data/set_3/input_sequences/input_res_params_concatenated.npy'\n",
    "with open(name, 'wb') as f:\n",
    "    #np.save(f, data_res)\n",
    "    #np.save(f, data_in_conc)\n",
    "name = '/Volumes/L7aler_HD 1/ADL_Project/AR_data/mag_flux_area_data/set_3/target_sequences/target_res_params_concatenated.npy'\n",
    "with open(name, 'wb') as f:\n",
    "    #np.save(f, target_res)\n",
    "    #np.save(f, target_conc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
