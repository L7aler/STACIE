{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "FLUX_DATA_DIR = 'C:\\\\Users\\\\Alberto\\\\Desktop\\\\uni_tmp\\\\ADL\\\\STACIE\\\\flux_prediction\\\\data\\\\magnetic_flux_area_data\\\\'\n",
    "LSTM_DATA_DIR = 'C:\\\\Users\\\\Alberto\\\\Desktop\\\\uni_tmp\\\\ADL\\\\STACIE\\\\flux_prediction\\\\data\\\\lstm_data\\\\multi_label_classification\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_inp = LSTM_DATA_DIR + 'train_input.npy'\n",
    "file_tar = LSTM_DATA_DIR + 'train_target.npy'\n",
    "\n",
    "train_input = np.load(file_inp)\n",
    "train_target = np.load(file_tar)\n",
    "\n",
    "file2_inp = LSTM_DATA_DIR + 'val_input.npy'\n",
    "file2_tar = LSTM_DATA_DIR + 'val_target.npy'\n",
    "\n",
    "val_input = np.load(file2_inp)\n",
    "val_target = np.load(file2_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#for n in np.argmax(train_target, axis=2):\n",
    "#    print(n, ' ', end='')\n",
    "\n",
    "a = np.argmax(train_target, axis=2).flatten()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_input = train_input\n",
    "t2_output = train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77738, 10, 40) (77738, 1, 5)\n"
     ]
    }
   ],
   "source": [
    "my_shape = t2_input.shape\n",
    "#my_shape = (my_shape[0], my_shape[1], my_shape[2] + 5)\n",
    "my_shape2 = t2_output.shape\n",
    "\n",
    "print(my_shape, my_shape2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = np.pad(t2_input, ((0,0), (0,0), (0,5)), mode='constant')\n",
    "array2 = np.pad(t2_output, ((0,0), (0,0), (40,0)), mode='constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate tutorial: https://pytorch-forecasting.readthedocs.io/en/stable/tutorials/stallion.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array2[500][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target[100,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call (Temp/ipykernel_42936/1092784536.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Alberto\\AppData\\Local\\Temp/ipykernel_42936/1092784536.py\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    fn = torch.sum(d, 'float'), axis=0)\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to function call\n"
     ]
    }
   ],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    EPSILON = 1e-7\n",
    "    y_pred = torch.round(y_pred)\n",
    "    a = y_true*y_pred\n",
    "    a.type(torch.FloatTensor)\n",
    "    tp = torch.sum(a, axis=0)\n",
    "    \n",
    "    b = (1-y_true)*(1-y_pred)\n",
    "    b.type(torch.FloatTensor)\n",
    "    tn = torch.sum(b, axis=0)\n",
    "    \n",
    "    c = (1-y_true)*y_pred\n",
    "    c.type(torch.FloatTensor)\n",
    "    fp = torch.sum(c, axis=0)\n",
    "    \n",
    "    d = y_true*(1-y_pred)\n",
    "    d.type(torch.FloatTensor)\n",
    "    fn = torch.sum(d, axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + EPSILON)\n",
    "    r = tp / (tp + fn + EPSILON)\n",
    "\n",
    "    f1 = 2*p*r / (p+r+EPSILON)\n",
    "    f1 = torch.where(torch.isnan(f1), torch.zeros_like(f1), f1)\n",
    "    return torch.mean(f1)\n",
    "\n",
    "\"\"\"\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lstm_src[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_trg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = np.load(os.path.join(FLUX_DATA_DIR, 'set_2', 'input_res_concatenated.npy'))\n",
    "targets = np.load(os.path.join(FLUX_DATA_DIR, 'set_2', 'target_res_concatenated.npy'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
