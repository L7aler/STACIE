{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "FLUX_DATA_DIR = 'C:\\\\Users\\\\Alberto\\\\Desktop\\\\uni_tmp\\\\ADL\\\\STACIE\\\\flux_prediction\\\\data\\\\magnetic_flux_area_data\\\\'\n",
    "LSTM_DATA_DIR = 'C:\\\\Users\\\\Alberto\\\\Desktop\\\\uni_tmp\\\\ADL\\\\STACIE\\\\flux_prediction\\\\data\\\\lstm_data\\\\multi_label_classification\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_inp = LSTM_DATA_DIR + 'train_input.npy'\n",
    "file_tar = LSTM_DATA_DIR + 'train_target.npy'\n",
    "\n",
    "train_input = np.load(file_inp)\n",
    "train_target = np.load(file_tar)\n",
    "\n",
    "file2_inp = LSTM_DATA_DIR + 'val_input.npy'\n",
    "file2_tar = LSTM_DATA_DIR + 'val_target.npy'\n",
    "\n",
    "val_input = np.load(file2_inp)\n",
    "val_target = np.load(file2_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = DataLoader(train_input, batch_size=256)\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " def split_classes(targets, n_classes=5):\n",
    "    index_list = [[] for _ in range(n_classes)]\n",
    "    for i, tgt in enumerate(targets):\n",
    "        class_idx = np.argmax(tgt[0])\n",
    "        index_list[class_idx].append(i)\n",
    "    for class_num in index_list:\n",
    "        print(len(class_num))\n",
    "    return index_list\n",
    "\n",
    "def downsample_data(sources, targets):\n",
    "    class_idx = split_classes(targets)\n",
    "    min_class = min([len(label) for label in class_idx])\n",
    "    out_idx = []\n",
    "    for class_list in class_idx:\n",
    "        if len(class_list) > min_class:\n",
    "            idx_list = np.random.choice(class_list, size=min_class, replace=False)\n",
    "            out_idx.extend(idx_list)\n",
    "        else:\n",
    "            out_idx.extend(class_list)\n",
    "    return sources[out_idx], targets[out_idx]\n",
    "\n",
    "def split_flare(targets):\n",
    "    noflare_idx = []\n",
    "    flare_idx = []\n",
    "    for i, tgt in enumerate(targets):\n",
    "        class_idx = np.argmax(tgt[0])\n",
    "        if class_idx == 0:\n",
    "            noflare_idx.append(i)\n",
    "        else:\n",
    "            flare_idx.append(i)\n",
    "    print(len(noflare_idx), len(flare_idx))\n",
    "    return noflare_idx, flare_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51614\n",
      "14614\n",
      "8963\n",
      "2321\n",
      "226\n",
      "1130 1130 1130\n"
     ]
    }
   ],
   "source": [
    "#idx = split_classes(train_target)\n",
    "#print(idx[-1])\n",
    "#class_5_tgt = train_target[idx[-1]]\n",
    "#print(class_5_tgt)\n",
    "new_sources, new_targets = downsample_data(train_input, train_target)\n",
    "print(len(new_sources), len(new_targets), 226*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_weights(targets):\n",
    "    class_num = np.zeros(5)\n",
    "    print(len(targets))\n",
    "    for tgt in targets:\n",
    "        label_idx = np.argmax(tgt[0])\n",
    "        class_num[label_idx] += 1\n",
    "    class_num = class_num/len(targets)\n",
    "    weights = np.ones(5) - class_num\n",
    "    return class_num, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77738\n",
      "[0.66394813 0.18799043 0.11529754 0.0298567  0.0029072 ]\n",
      "[0.33605187 0.81200957 0.88470246 0.9701433  0.9970928 ]\n"
     ]
    }
   ],
   "source": [
    "c, w = label_weights(train_target)\n",
    "print(c)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77738, 10, 40)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24683, 10, 40)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = np.concatenate((train_input, val_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102421, 10, 40)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#for n in np.argmax(train_target, axis=2):\n",
    "#    print(n, ' ', end='')\n",
    "\n",
    "a = np.argmax(train_target, axis=2).flatten()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_input = train_input\n",
    "t2_output = train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77738, 10, 40) (77738, 1, 5)\n"
     ]
    }
   ],
   "source": [
    "my_shape = t2_input.shape\n",
    "#my_shape = (my_shape[0], my_shape[1], my_shape[2] + 5)\n",
    "my_shape2 = t2_output.shape\n",
    "\n",
    "print(my_shape, my_shape2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = np.pad(t2_input, ((0,0), (0,0), (0,5)), mode='constant')\n",
    "array2 = np.pad(t2_output, ((0,0), (0,0), (40,0)), mode='constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate tutorial: https://pytorch-forecasting.readthedocs.io/en/stable/tutorials/stallion.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array2[500][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target[100,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.Tensor([[ 0.0825,  0.1514],\n",
    "        [ 1.0017, -0.9427],\n",
    "        [-0.2009,  0.5858],\n",
    "        [ 0.5714, -0.4565],\n",
    "        [ 1.1508, -1.1926],\n",
    "        [ 1.2249, -1.2643],\n",
    "        [ 1.0297, -1.0032],\n",
    "        [ 0.1368,  0.1709],\n",
    "        [ 0.8833, -0.8309],\n",
    "        [-0.0853,  0.2499],\n",
    "        [ 1.2265, -1.2521],\n",
    "        [ 1.1567, -1.2178],\n",
    "        [ 0.4999, -0.3505],\n",
    "        [ 1.2842, -1.3214],\n",
    "        [ 1.0780, -1.1057],\n",
    "        [ 0.4917, -0.2947],\n",
    "        [ 0.3241, -0.0980],\n",
    "        [ 0.8195, -0.7421],\n",
    "        [ 0.9674, -1.0017],\n",
    "        [ 0.3735, -0.2303],\n",
    "        [ 0.4533, -0.2839],\n",
    "        [ 0.2105,  0.0082],\n",
    "        [ 0.6989, -0.7105],\n",
    "        [-0.7834,  0.8882],\n",
    "        [ 0.0805,  0.1199],\n",
    "        [ 0.2665,  0.0696],\n",
    "        [ 0.8326, -0.7673],\n",
    "        [ 0.3153, -0.0355],\n",
    "        [ 1.0380, -1.1166],\n",
    "        [ 0.8410, -0.7189],\n",
    "        [ 0.2861, -0.2109],\n",
    "        [ 0.9142, -0.8246],\n",
    "        [ 0.1956,  0.1142],\n",
    "        [ 0.2774,  0.0247],\n",
    "        [ 0.5453, -0.3120],\n",
    "        [ 1.1921, -1.3566],\n",
    "        [ 0.1720, -0.0827],\n",
    "        [ 1.0999, -1.1057],\n",
    "        [ 1.0848, -1.1121],\n",
    "        [ 0.3071, -0.1220],\n",
    "        [ 0.4445, -0.3426],\n",
    "        [ 1.0167, -0.9883],\n",
    "        [ 0.8781, -0.6220]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32728/1521731468.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mlabel_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "dim=2\n",
    "            \n",
    "label_idx = torch.argmax(t, dim=1)\n",
    "print(label_idx)\n",
    "\n",
    "#label_idx = label_idx[:, 0]\n",
    "#print(label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class F1Score:\n",
    "    \"\"\"\n",
    "    Class for f1 calculation in Pytorch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, average: str = 'weighted'):\n",
    "        \"\"\"\n",
    "        Init.\n",
    "\n",
    "        Args:\n",
    "            average: averaging method\n",
    "        \"\"\"\n",
    "        self.average = average\n",
    "        if average not in [None, 'micro', 'macro', 'weighted']:\n",
    "            raise ValueError('Wrong value of average parameter')\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_f1_micro(predictions: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate f1 micro.\n",
    "\n",
    "        Args:\n",
    "            predictions: tensor with predictions\n",
    "            labels: tensor with original labels\n",
    "\n",
    "        Returns:\n",
    "            f1 score\n",
    "        \"\"\"\n",
    "        true_positive = torch.eq(labels, predictions).sum().float()\n",
    "        f1_score = torch.div(true_positive, len(labels))\n",
    "        return f1_score\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_f1_count_for_label(predictions: torch.Tensor,\n",
    "                                labels: torch.Tensor, label_id: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Calculate f1 and true count for the label\n",
    "\n",
    "        Args:\n",
    "            predictions: tensor with predictions\n",
    "            labels: tensor with original labels\n",
    "            label_id: id of current label\n",
    "\n",
    "        Returns:\n",
    "            f1 score and true count for label\n",
    "        \"\"\"\n",
    "        # label count\n",
    "        true_count = torch.eq(labels, label_id).sum()\n",
    "\n",
    "        # true positives: labels equal to prediction and to label_id\n",
    "        true_positive = torch.logical_and(torch.eq(labels, predictions),\n",
    "                                          torch.eq(labels, label_id)).sum().float()\n",
    "        # precision for label\n",
    "        precision = torch.div(true_positive, torch.eq(predictions, label_id).sum().float())\n",
    "        # replace nan values with 0\n",
    "        precision = torch.where(torch.isnan(precision),\n",
    "                                torch.zeros_like(precision).type_as(true_positive),\n",
    "                                precision)\n",
    "\n",
    "        # recall for label\n",
    "        recall = torch.div(true_positive, true_count)\n",
    "        # f1\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        # replace nan values with 0\n",
    "        f1 = torch.where(torch.isnan(f1), torch.zeros_like(f1).type_as(true_positive), f1)\n",
    "        return f1, true_count\n",
    "\n",
    "    def __call__(self, predictions: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate f1 score based on averaging method defined in init.\n",
    "\n",
    "        Args:\n",
    "            predictions: tensor with predictions\n",
    "            labels: tensor with original labels\n",
    "\n",
    "        Returns:\n",
    "            f1 score\n",
    "        \"\"\"\n",
    "\n",
    "        # simpler calculation for micro\n",
    "        if self.average == 'micro':\n",
    "            return self.calc_f1_micro(predictions, labels)\n",
    "\n",
    "        f1_score = 0\n",
    "        for label_id in range(len(labels.unique())):\n",
    "            f1, true_count = self.calc_f1_count_for_label(predictions, labels, label_id)\n",
    "\n",
    "            if self.average == 'weighted':\n",
    "                f1_score += f1 * true_count\n",
    "            elif self.average == 'macro':\n",
    "                f1_score += f1\n",
    "\n",
    "        if self.average == 'weighted':\n",
    "            f1_score = torch.div(f1_score, len(labels))\n",
    "        elif self.average == 'macro':\n",
    "            f1_score = torch.div(f1_score, len(labels.unique()))\n",
    "\n",
    "        return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.randint(0, 10, (4096, 100)).flatten()\n",
    "predictions = torch.randint(0, 10, (4096, 100)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 3, 1,  ..., 5, 4, 7])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1007) 0.10068788783404362\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels1 = labels.numpy()\n",
    "predictions1 = predictions.numpy()\n",
    "\n",
    "f1_metric = F1Score('macro')\n",
    "my_pred = f1_metric(predictions, labels)\n",
    "\n",
    "f1_pred = f1_score(labels1, predictions1, average='macro')\n",
    "\n",
    "print(my_pred, f1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef f1_loss(y_true, y_pred):\\n    \\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\\n    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\\n\\n    p = tp / (tp + fp + K.epsilon())\\n    r = tp / (tp + fn + K.epsilon())\\n\\n    f1 = 2*p*r / (p+r+K.epsilon())\\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\\n    return 1 - K.mean(f1)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    EPSILON = 1e-7\n",
    "    y_pred = torch.round(y_pred)\n",
    "    a = y_true*y_pred\n",
    "    a.type(torch.FloatTensor)\n",
    "    tp = torch.sum(a, axis=0)\n",
    "    \n",
    "    b = (1-y_true)*(1-y_pred)\n",
    "    b.type(torch.FloatTensor)\n",
    "    tn = torch.sum(b, axis=0)\n",
    "    \n",
    "    c = (1-y_true)*y_pred\n",
    "    c.type(torch.FloatTensor)\n",
    "    fp = torch.sum(c, axis=0)\n",
    "    \n",
    "    d = y_true*(1-y_pred)\n",
    "    d.type(torch.FloatTensor)\n",
    "    fn = torch.sum(d, axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + EPSILON)\n",
    "    r = tp / (tp + fn + EPSILON)\n",
    "\n",
    "    f1 = 2*p*r / (p+r+EPSILON)\n",
    "    f1 = torch.where(torch.isnan(f1), torch.zeros_like(f1), f1)\n",
    "    return torch.mean(f1)\n",
    "\n",
    "\"\"\"\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heads : 4\n",
      "Dimension : 64\n",
      "Encoding layers : 4\n",
      "Encoder : pos\n",
      "Loss function : cross entropy\n",
      "Optimizer : adam\n",
      "Learning rate : 2e-05\n",
      "Batch size : 16\n",
      "Epochs : 20\n",
      "Device : cuda:0\n",
      "Output name : cagasbura\n"
     ]
    }
   ],
   "source": [
    "NHEADS=4\n",
    "MODEL_DIM=64\n",
    "ENC_LAYERS=4\n",
    "ENCODER='pos'\n",
    "loss_str='cross entropy'\n",
    "OPTIM='adam'\n",
    "lr=2e-5\n",
    "BATCH_SIZE=16\n",
    "EPOCHS=20\n",
    "DEV='cuda:0'\n",
    "OUT_NAME='cagasbura'\n",
    "print(f'Heads : {NHEADS}\\nDimension : {MODEL_DIM}\\nEncoding layers : {ENC_LAYERS}')\n",
    "\n",
    "print(f'Encoder : {ENCODER}\\nLoss function : {loss_str}\\nOptimizer : {OPTIM}\\nLearning rate : {lr}')\n",
    "print(f'Batch size : {BATCH_SIZE}\\nEpochs : {EPOCHS}\\nDevice : {DEV}\\nOutput name : {OUT_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
